{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace0c6cc-1e40-4dba-be23-e1f91c68f9b5",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1596ae92-2fff-41d3-8f0b-1ea5661ba1af",
   "metadata": {},
   "source": [
    "Variational Quantum Algorithms (VQAs) are becoming increasingly significant with the advancement of quantum computing technologies. However, the benchmarking of such algorithms remains fragmented, with most existing benchmarks relying either on classical datasets mapped to quantum representations or on custom datasets created for specific research purposes. This lack of standardization hinders fair and reproducible evaluation of quantum machine learning pipelines. In this project, we address this gap by revamping the Datasets module of the Qiskit Machine Learning repository. Our contributions include the systematic standardization of dataset generators, enabling consistent and reproducible benchmarking of VQAs. This work lays the foundation for a more robust evaluation framework and facilitates future developments in quantum machine learning research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d92ea5c-ca51-4e2a-acf4-b8cc07df9bd6",
   "metadata": {},
   "source": [
    "# Motivation & Previous Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca36003d-8e2b-41c4-8539-7026838e48b4",
   "metadata": {},
   "source": [
    "Recent literature has discussed that to really search for Quantum advantage, we first have to start using natively quantum datasets. This is because benchmarking the pipeline when a feature map has been used to map classical data to quantum features will invariably also include the performance of the feature-map in the benchmark. In efforts towards this, Qiskit ML repository already had a natively quantum toy dataset called the `ad_hoc_data`. \n",
    "\n",
    "While the original implementation was contraint to 2 and 3 qubits, our refactoring initiative aimed to generalize this dataset generator to support arbitrary qubit counts while preserving its core mathematical structure. This dataset encodes data vectors $\\vec{x} \\in (0, 2\\pi]^n$ through a parameterized quantum circuit:\n",
    "\n",
    "\n",
    "$$U_{\\Phi}(\\vec{x}) = \\exp\\left(i\\sum_{S \\subseteq [n]}\\phi_S(\\vec{x})\\prod_{i\\in S}Z_i\\right)$$\n",
    "\n",
    "where $\\phi_{\\{i,j\\}} = (\\pi-x_i)(\\pi-x_j)$ and $\\phi_{\\{i\\}} = x_i$. Then the labels are assigned with the below expression, where V is a random unitary.\n",
    "\n",
    "$$m(\\vec{x}) = \\text{sign}\\left(\\langle\\Phi(\\vec{x})|V^\\dagger\\left(\\prod_i Z_i\\right)V|\\Phi(\\vec{x})\\rangle\\right)$$\n",
    "\n",
    "Below is an example call of our re-factored Ad Hoc that can run for any number of qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a98091d8-7135-4996-ad94-f8c9b12b5078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.882813 s\n",
      "(200000, 256, 1) (200000, 2) [[[-0.03102683+0.01821032j]\n",
      "  [ 0.03273911+0.06978137j]\n",
      "  [-0.01073349-0.01157602j]\n",
      "  ...\n",
      "  [-0.00187201+0.02382701j]\n",
      "  [-0.01902454-0.04338348j]\n",
      "  [ 0.03132947+0.01186094j]]\n",
      "\n",
      " [[ 0.04245913+0.01339607j]\n",
      "  [-0.01755919-0.00327305j]\n",
      "  [-0.0421539 +0.09837246j]\n",
      "  ...\n",
      "  [-0.05324089+0.00456716j]\n",
      "  [-0.04564579+0.02327108j]\n",
      "  [ 0.05332191+0.01937745j]]\n",
      "\n",
      " [[-0.00174141+0.00225008j]\n",
      "  [ 0.02233321-0.12677285j]\n",
      "  [-0.02055231+0.00794574j]\n",
      "  ...\n",
      "  [ 0.0234014 -0.05031609j]\n",
      "  [-0.06779369-0.02058058j]\n",
      "  [ 0.04085395+0.02256062j]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.00948967-0.04619195j]\n",
      "  [-0.02238625-0.11372839j]\n",
      "  [ 0.05672997+0.01039174j]\n",
      "  ...\n",
      "  [ 0.04229421-0.02849684j]\n",
      "  [ 0.00091702-0.00915222j]\n",
      "  [ 0.05536808-0.00716505j]]\n",
      "\n",
      " [[-0.0317338 +0.05295308j]\n",
      "  [ 0.02866339+0.01782857j]\n",
      "  [-0.0660053 +0.04523696j]\n",
      "  ...\n",
      "  [-0.03769681-0.07213433j]\n",
      "  [-0.06995552+0.06203371j]\n",
      "  [ 0.01410807+0.05502951j]]\n",
      "\n",
      " [[-0.03686306-0.02279928j]\n",
      "  [ 0.01298147-0.04450951j]\n",
      "  [ 0.03570063-0.06516567j]\n",
      "  ...\n",
      "  [-0.07812331+0.01860841j]\n",
      "  [-0.06128532-0.01705762j]\n",
      "  [-0.04508572-0.02872525j]]] [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "from qiskit_machine_learning.datasets import ad_hoc_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd3e04b-8308-4cbc-a731-d2e398b188ea",
   "metadata": {},
   "source": [
    "Following this, we propose three new datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
